# -*- coding: utf-8 -*-
"""pract6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_7SQB-WgDIoKTs52UuZIyScOBVDHdyiz

Implement K-Means clustering/ hierarchical clustering on sales_data_sample.csv dataset.
Determine the number of clusters using the elbow method.
Dataset link : https://www.kaggle.com/datasets/kyanyoga/sample-sales-data
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler

df = pd.read_csv('sales_data_sample.csv',encoding='unicode_escape')
#df = pd.read_csv('sales_data_sample.csv')
df.head()

df.info()

df.dtypes

df = df.drop(columns=['ADDRESSLINE1', 'ADDRESSLINE2', 'POSTALCODE', 'CITY', 'TERRITORY', 'PHONE',
                      'STATE', 'CONTACTFIRSTNAME', 'CONTACTLASTNAME', 'CUSTOMERNAME', 'ORDERNUMBER',
                      'ORDERDATE', 'STATUS', 'MONTH_ID', 'QTR_ID', 'YEAR_ID'])

df.columns

df.head()

from sklearn.preprocessing import LabelEncoder

categories = ['PRODUCTLINE', 'PRODUCTCODE', 'COUNTRY', 'DEALSIZE']
le = LabelEncoder()
for col in categories:
    df[col] = le.fit_transform(df[col])

# Standardize the data
data = StandardScaler().fit_transform(df)

df.head()

"""##### Finding optimal numbers of clusters is elbow method </br> For each value of K, we are calculating WCSS ( Within-Cluster Sum of Square ). WCSS is the sum of squared distance between each point and the centroid in a cluster.When we plot the WCSS with the K value, the plot looks like an Elbow"""

from sklearn.cluster import KMeans
wcss = []
for k in range(1,15):
    kmeans = KMeans(n_clusters=k,init='k-means++',random_state=15)
    kmeans.fit(data)
    wcss.append(kmeans.inertia_)

#The wcss list (which stands for "within-cluster sum of squares") is initialized. This will be used to store the inertia values for different numbers of clusters. The inertia is a measure of how tightly the clusters are packed together. Lower inertia values indicate better clustering.

k = list(range(1,15))
plt.plot(k,wcss)
plt.xlabel('Clusters')
plt.ylabel('scores')
plt.title('Finding right number of clusters')
plt.grid()
plt.show()

from scipy.cluster.hierarchy import dendrogram, linkage
# Hierarchical Clustering
linked = linkage(data, method='ward')

dendrogram(linked, orientation='top')

